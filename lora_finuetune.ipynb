{"cells":[{"cell_type":"markdown","id":"8103e148-b234-4dc2-86be-d16463478344","metadata":{},"source":["## Step1. lora微调模型"]},{"cell_type":"markdown","id":"b76ac97a-7e3f-4f73-bd59-bad6b701d979","metadata":{},"source":["**本示例采用qwen2-7B-instruct作为base模型，利用peft框架来进行lora微调。\n","主要流程为：①导入模型、指令微调数据集；②编写处理上下文的帮手函数；③设置lora参数；④训练**"]},{"cell_type":"markdown","id":"7271028b","metadata":{},"source":["对于解析pdf，我觉得可以使用pymupdf"]},{"cell_type":"markdown","id":"dd44c0fb-9306-4dcf-8326-fe7670efee01","metadata":{},"source":["### 下载环境\n"]},{"cell_type":"code","execution_count":2,"id":"bb2f62dc-b6dd-4d5b-bde0-e4f8558a1188","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://mirrors.ivolces.com/pypi/simple/\n","Requirement already satisfied: torch in /root/miniconda3/lib/python3.10/site-packages (1.13.1+cu117)\n","Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.10/site-packages (from torch) (4.12.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://mirrors.ivolces.com/pypi/simple/\n","Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.10/site-packages (4.65.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://mirrors.ivolces.com/pypi/simple/\n","Collecting accelerate\n","  Downloading https://mirrors.ivolces.com/pypi/packages/15/33/b6b4ad5efa8b9f4275d4ed17ff8a44c97276171341ba565fdffb0e3dc5e8/accelerate-0.33.0-py3-none-any.whl (315 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.17 in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (23.0)\n","Requirement already satisfied: psutil in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (5.9.0)\n","Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (1.13.1+cu117)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (0.24.6)\n","Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.10/site-packages (from accelerate) (0.4.4)\n","Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n","Requirement already satisfied: requests in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.29.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.33.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#下载环境\n","!pip install transformers>=4.37.0\n","!pip install torch\n","# !pip install PyPDF2\n","!pip install docling\n","!pip install tqdm\n","!pip install accelerate\n","!pip install scikit-learn"]},{"cell_type":"code","execution_count":1,"id":"76b4e665-330f-4e39-a8b5-03e8dc2676bf","metadata":{},"outputs":[],"source":["import os\n","import re\n","import sys\n","import json\n","import warnings\n","# import PyPDF2\n","from tqdm import tqdm\n","from transformers import AutoModelForCausalLM,AutoTokenizer,Trainer,TrainingArguments\n","from torch.utils.data import Dataset\n","import copy\n","import torch\n","from pathlib import Path\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from docling.document_converter import DocumentConverter"]},{"cell_type":"markdown","id":"91862110-c6a2-4fe8-9426-bdb27cdd2ce4","metadata":{},"source":["### 定义训练集、模型、上下文路径\n"]},{"cell_type":"code","execution_count":2,"id":"c23ae9f7-6dd5-4c00-8596-d79503020c97","metadata":{},"outputs":[],"source":["#导入你自己构建的微调数据集\n","train_input_path='/root/code/LLM_pdf/LLM_pipline/finetune_exmaple.jsonl'\n","\n","#导入可能用到的上下文目录路径\n","PDF_PATH='/root/code/pdfs'\n","\n","device=\"cuda\"\n","local_docling_model_path = Path(\"/root/.cache/huggingface/hub/models--ds4sd--docling-models/snapshots/96e8ba4eb46f125ff2abbbdffbdc2a102d0150b4/\")\n","converter = DocumentConverter(artifacts_path=local_docling_model_path)\n","\n","#导入base模型\n","model_path=\"/vepfs/fs_users/lkn/huggingface/hub\"  #qwen2-7B-Instruct"]},{"cell_type":"markdown","id":"9a675557-a65d-4dfe-9964-b9e48f78c45d","metadata":{},"source":["### 定义帮手函数（用于处理上下文，解析pdf）"]},{"cell_type":"code","execution_count":4,"id":"3348c78c","metadata":{},"outputs":[],"source":["\n","\n","\n","\n","# # 示例数据\n","# data = {\n","#     'file-info': {\n","#         'filename': '10.1002_adem.201700820.pdf',\n","#         'document-hash': '81329a6ee2745cda5505cb8eab0680caf18aab9b1d12bace90e9e43e6f72636c',\n","#         '#-pages': 7\n","#     },\n","#     'main-text': [\n","#         {'text': 'FULL PAPER', 'type': 'page-header', 'name': 'Page-header', 'prov': [{'bbox': [50.91675567626953, 752.8856201171875, 129.98294067382812, 765.4323120117188], 'page': 1, 'span': [0, 10]}]},\n","#         {'text': 'Full Papers', 'type': 'paragraph', 'name': 'Text', 'prov': [{'bbox': [50.53390121459961, 735.7875366210938, 88.59913635253906, 744.0340576171875], 'page': 1, 'span': [0, 11]}]},\n","#         {'text': 'www.aem-journal.com', 'type': 'paragraph', 'name': 'Text', 'prov': [{'bbox': [472.0702209472656, 735.7813110351562, 547.0069580078125, 743.63330078125], 'page': 1, 'span': [0, 19]}]},\n","#         {'text': 'Effects of Initial δ Phase on Creep Behaviors and Fracture Characteristics of a Nickel-Based Superalloy', 'type': 'subtitle-level-1', 'name': 'Section-header', 'prov': [{'bbox': [51.02360153198242, 674.0831298828125, 496.2049865722656, 717.9251098632812], 'page': 1, 'span': [0, 103]}]},\n","#         {'text': 'Y. C. Lin,* Liang-Xing Yin, Shun-Cun Luo, Dao-Guang He, and Xiao-Bin Peng', 'type': 'paragraph', 'name': 'Text', 'prov': [{'bbox': [50.96749496459961, 643.3577270507812, 495.8893127441406, 657.5748901367188], 'page': 1, 'span': [0, 73]}]},\n","#         {'text': '1700820 (1 of 7)', 'type': 'page-footer', 'name': 'Page-footer', 'prov': [{'bbox': [267.6825256347656, 37.788795471191406, 330.2043762207031, 47.574771881103516], 'page': 1, 'span': [0, 16]}]},\n","#         {'text': 'alloy, etc. Lin et al. [55] investigated the fracture characteristics of a typical Ni-based superalloy, and found that the combined effects of localized necking and microvoid coalescence cause the final fracture of specimens.', 'type': 'paragraph', 'name': 'Text', 'prov': [{'bbox': [304.8879699707031, 69.45539855957031, 553.051025390625, 431.31536865234375], 'page': 1, 'span': [0, 2100]}]},\n","#         {'name': 'Picture', 'type': 'figure', '$ref': '#/figures/0'}\n","#     ],\n","#     'figures': [\n","#         {'caption': 'Figure 7. SEM fractographs of creep-ruptured nickel-based superalloy...'}\n","#     ]\n","# }\n","\n","# 使用Docling提取PDF内容\n","def extract_pdf_content(pdf_path,converter):\n","    \n","    # print(pdf_path)\n","    print(\"begin! :\", pdf_path)\n","    doc = converter.convert_single(pdf_path)\n","    print(\"end! :\", pdf_path)\n","    torch.cuda.empty_cache()\n","    return doc.render_as_dict()\n","\n","# 提取主文本内容并添加页码信息\n","def extract_main_text(data, pages=None):\n","    main_text = []\n","    for element in data.get('main-text', []):\n","        # 检查每个条目是否具有 prov 属性\n","        if 'prov' in element and element['prov']:\n","            page_number = element['prov'][0]['page']\n","        else:\n","            page_number = 'unknown'  # 标记为未知页码\n","        if pages and int(page_number) not in pages:\n","            continue  # 如果页面不在指定范围内，跳过该页面\n","        # 如果存在 $ref 字段，替换为引用的内容\n","        if '$ref' in element:\n","            ref = element['$ref']\n","            ref_index = int(ref.split('/')[-1])\n","            element_content = data.get('figures', [])[ref_index]\n","            main_text.append({\n","                'page': page_number,\n","                'type': element.get('type', 'unknown'),\n","                'name': element.get('name', 'unknown'),\n","                'text': element_content  # 使用引用内容替换\n","            })\n","        else:\n","            main_text.append({\n","                'page': page_number,\n","                'type': element.get('type', 'unknown'),\n","                'name': element.get('name', 'unknown'),\n","                'text': element.get('text', '')\n","            })\n","    return main_text\n","\n","# 将表格数据转换为字符串，用于检索\n","def table_to_text(table):\n","    return table.get('title') + '\\n' + '\\n'.join(['\\t'.join(row) for row in table.get('data', [])])\n","\n","# 提取表格内容并添加页码信息\n","def extract_tables(data, pages = None):\n","    tables = []\n","    for table in data.get('tables', []):\n","        page_number = table['prov'][0]['page']\n","        if pages and int(page_number) not in pages:\n","            continue  # 如果页面不在指定范围内，跳过该页面\n","        table_data = {\n","            'page': page_number,\n","            'title': table.get('text', ''),\n","            'type': table.get('type', 'unknown'),\n","            'columns': table.get('#-cols', 0),\n","            'rows': table.get('#-rows', 0),\n","            'text': ''\n","        }\n","        table_text = table.get('title', '') + '\\n'\n","        table_text += '\\n'.join(['\\t'.join(cell.get('text', '') for cell in row) for row in table.get('data', [])])\n","        table_data['text'] = table_text\n","        tables.append(table_data)\n","    return tables\n","\n","# 将表格信息组合成字符串\n","def combine_table_info(table):\n","    return f\"Title: {table['title']}\\nColumns: {table['columns']}\\nRows: {table['rows']}\\n{table['text']}\"\n","\n","# 构建最终的JSON结构\n","def build_final_json(data, pages = None):\n","    main_texts = extract_main_text(data, pages)\n","    tables = extract_tables(data, pages)\n","    combined_content = []\n","\n","    for item in main_texts:\n","        combined_content.append(item)\n","    \n","    # 将表格对象转换为统一的结构\n","    for table in tables:\n","        combined_content.append({\n","            'page': table['page'],\n","            'type': table['type'],\n","            'name': table['title'],\n","            'text': combine_table_info(table),\n","        })\n","\n","    return {\n","        'filename': data['file-info']['filename'],\n","        'number-of-pages': data['file-info']['#-pages'],\n","        'combined-content': combined_content\n","    }\n","    \n","# 检索和组合PDF内容\n","def parse_pdf_and_concate(obj, converter):\n","    pdf_path = obj[\"doi\"].replace('/', '_').replace(' (Supporting Information)', '_si') + '.pdf'\n","    pdf_path = os.path.join(PDF_PATH, pdf_path)\n","    task_type = obj[\"task\"]\n","    if task_type == \"1\":\n","        obj[\"input\"].append({\"role\": \"user\", \"content\": \"\"})\n","        return\n","    if \"pages\" in obj and obj[\"pages\"] != [1, -1]:\n","        pages = range(obj[\"pages\"][0], obj[\"pages\"][1] + 1)\n","    else:\n","        pages = None\n","    # print(pdf_path)\n","    try:\n","        if not os.path.exists(pdf_path):\n","            raise FileNotFoundError(f\"PDF file does not exist: {pdf_path}\")\n","        data = extract_pdf_content(pdf_path,converter)\n","    \n","\n","        # 构建最终的JSON结构\n","        final_json = build_final_json(data,pages=pages)\n","        # print(final_json)\n","        # 提取问题作为关键词\n","        question = next((entry[\"content\"] for entry in obj[\"input\"] if entry[\"role\"] == \"user\"), \"\")\n","\n","        all_texts = [\n","                element['text'] if isinstance(element['text'], str) else json.dumps(element['text'])\n","                for element in final_json['combined-content']\n","            ]\n","        \n","            # 初始化 TfidfVectorizer 实例\n","        torch.cuda.empty_cache()\n","        print(\"begin for vectorizer\")\n","        tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n","\n","        # 对所有文档进行拟合（学习词汇表和IDF）\n","        fitted_vectorizer = tfidf_vectorizer.fit(all_texts)\n","        print(\"fit vectorizer\")\n","        # 将文档集合转换为TF-IDF特征矩阵\n","        tfidf_vectorizer_vectors = fitted_vectorizer.transform(all_texts)\n","\n","        # 将问题转换为与文档集合相同空间的TF-IDF向量\n","        question_vec = fitted_vectorizer.transform([question])\n","        print(\"transform vectorizer\")\n","\n","        # 计算余弦相似度\n","        cosine_similarities = cosine_similarity(question_vec, tfidf_vectorizer_vectors).flatten()\n","        print(\"end vectorizer\")\n","\n","        # 找到最相关的内容索引\n","        relevant_content_indices = cosine_similarities.argsort()[-5:][::-1]  # 选择最相关的5个内容\n","\n","        # 构建初步上下文\n","        relevant_contents = [all_texts[i] for i in relevant_content_indices]\n","    except Exception as e:\n","        print(\"Error PDF is: \", pdf_path)\n","        relevant_contents=\"\"\n","    attached_file_content = \"\\nThe file is as follows:\\n\\n\" + \" \".join(relevant_contents)\n","\n","    # 选择性获取上下文信息，限制长度\n","    attached_file_content = attached_file_content[:1024]\n","    obj[\"input\"].append({\"role\": \"user\", \"content\": attached_file_content})\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":7,"id":"d50b0f26","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["An unexpected error occurred while opening the document 10.1016_j.matchar.2018.06.029.pdf\n","Traceback (most recent call last):\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/datamodel/document.py\", line 93, in __init__\n","    self._backend = pdf_backend(\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/backend/docling_parse_backend.py\", line 193, in __init__\n","    self._pdoc = pdfium.PdfDocument(path_or_stream)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 78, in __init__\n","    self.raw, to_hold, to_close = _open_pdf(self._input, self._password, self._autoclose)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 678, in _open_pdf\n","    raise PdfiumError(f\"Failed to load document (PDFium: {pdfium_i.ErrorToStr.get(err_code)}).\")\n","pypdfium2._helpers.misc.PdfiumError: Failed to load document (PDFium: Data format error).\n"]},{"name":"stdout","output_type":"stream","text":["begin! : /root/code/pdfs/10.1016_j.matchar.2018.06.029.pdf\n"]},{"ename":"RuntimeError","evalue":"Conversion failed with status: 3","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_pdf_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/root/code/pdfs/10.1016_j.matchar.2018.06.029.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mextract_pdf_content\u001b[0;34m(pdf_path, converter)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_pdf_content\u001b[39m(pdf_path,converter):\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# print(pdf_path)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin! :\u001b[39m\u001b[38;5;124m\"\u001b[39m, pdf_path)\n\u001b[0;32m---> 28\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend! :\u001b[39m\u001b[38;5;124m\"\u001b[39m, pdf_path)\n\u001b[1;32m     30\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/docling/document_converter.py:137\u001b[0m, in \u001b[0;36mDocumentConverter.convert_single\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    132\u001b[0m     conv_res: ConversionResult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(conv_res_iter)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conv_res\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    134\u001b[0m     ConversionStatus\u001b[38;5;241m.\u001b[39mSUCCESS,\n\u001b[1;32m    135\u001b[0m     ConversionStatus\u001b[38;5;241m.\u001b[39mPARTIAL_SUCCESS,\n\u001b[1;32m    136\u001b[0m }:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed with status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconv_res\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv_res\n","\u001b[0;31mRuntimeError\u001b[0m: Conversion failed with status: 3"]}],"source":["extract_pdf_content(\"/root/code/pdfs/10.1016_j.matchar.2018.06.029.pdf\",converter)\n","\n"]},{"cell_type":"code","execution_count":12,"id":"6bd0fa7b","metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":11,"id":"8ae6e06e-d8b9-47eb-a8e4-50b16fd1eae2","metadata":{},"outputs":[],"source":["# #  从PDF文件中提取文本，并以字符串列表的形式返回。\n","# #    参数：\n","# #        pdf_path: PDF文件的路径。\n","# #        add_page_num: 是否在每页文本的开头添加页码。\n","# #    返回：\n","# #        texts: 一个字符串列表，其中每个字符串都是一页的文本。\n","\n","# def extract_text(pdf_path, ) -> list[str]:\n","#     texts = []\n","#     try:\n","#         # Open the PDF file\n","#         doc = fitz.open(pdf_path)\n","#         for page_num in range(doc.page_count):\n","#             page = doc.load_page(page_num)\n","#             text = page.get_text(\"text\")  # Extract text from the page\n","#             if text:\n","#                 text = f\"Page {page_num + 1}:\\n{text}\\n\"\n","#                 texts.append(text)\n","#     except Exception as e:\n","#         print(f\"Error while processing PDF: {e}\")\n","#     return texts\n","\n","\n","# #读取doi字段，根据路径去解析相应的pdf，并根据\"pages\"字段来截取需要的上下文，把上下文作为user prompt append进原来的input list\n","# def parse_pdf_and_concate(obj):\n","#     pdf_path=obj[\"doi\"]\n","#     pdf_path = pdf_path.replace('/', '_').replace(' (Supporting Information)', '_si')\n","#     pdf_path=PDF_PATH+pdf_path+'.pdf'\n","#     attach_content_list=extract_text(pdf_path=pdf_path)\n","#     if \"pages\" in obj and obj[\"pages\"] != [1,-1] :\n","#         #例如 pages=[5,6] 代表attach_content_list 中第4个str和第五个str\n","#         index=obj[\"pages\"]\n","#         attach_content_list=attach_content_list[index[0]-1:index[1]]\n","    \n","#     attached_file_content = \"\\nThe file is as follows:\\n\\n\" + \"\".join(attach_content_list)\n","#     #  选择性的获取上下文信息，而不是全部内容\n","#     attached_file_content = attached_file_content[:1024]   \n","#     obj[\"input\"].append({\"role\":\"user\",\"content\":attached_file_content})\n"]},{"cell_type":"markdown","id":"545e3a0d-2e00-4205-9110-c260a6806736","metadata":{},"source":["### 导入模型和tokenzier"]},{"cell_type":"code","execution_count":5,"id":"497cd143-f362-484f-9c8f-f6e268992b19","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5123b7ac3d884fa4bb2bb308028e229d","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#导入模型\n","local_cache_dir = \"/vepfs/fs_users/lkn/huggingface/hub\"\n","\n","# 加载模型和分词器时指定 cache_dir\n","tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\", cache_dir=local_cache_dir)\n","model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-7B-Instruct\", cache_dir=local_cache_dir,torch_dtype=torch.float16)\n"]},{"cell_type":"code","execution_count":6,"id":"5b14fdf6-ad51-430a-8783-7e3f1b63c3b8","metadata":{},"outputs":[],"source":["#工具函数，读取测试集jsonl到list\n","def read_jsonl(file_path):    \n","    data=[]\n","    with open(file_path,'r',encoding='utf-8') as f:\n","        for line in f:\n","            try:\n","                obj=json.loads(line.strip())\n","                data.append(obj)\n","            except json.JSONDecodeError as e :\n","                print(f\"Error decoding JSON:{e}\")\n","    return data\n","\n","train_data=read_jsonl(train_input_path)\n","\n","#帮手函数，提取ideal的值，因为ideal有可能是个list，也可能是个str\n","def extract_ideal_value(ideal):\n","    if isinstance(ideal, list) and len(ideal) > 0:\n","        return ideal[0]\n","    elif isinstance(ideal, str):\n","        return ideal\n","    else:\n","        return None  "]},{"cell_type":"code","execution_count":33,"id":"3f5fd081","metadata":{},"outputs":[{"data":{"text/plain":["{'input': [{'role': 'system',\n","   'content': 'You are a highly intelligent assistant who answers the following multiple choice question correctly.'},\n","  {'role': 'system', 'content': ''},\n","  {'role': 'system', 'content': 'Only write the answer down.'},\n","  {'role': 'user',\n","   'content': 'Which of these evolutionary agents is most consistent at causing populations to become better suited to their environments over the course of generations?\\n\\na) Mutation\\n\\nb) Non-random mating\\n\\nc) Gene flow\\n\\nd) Natural selection'},\n","  {'role': 'assistant', 'content': 'd) Natural selection'},\n","  {'role': 'assistant', 'content': 'd) Natural selection'},\n","  {'role': 'assistant', 'content': 'd) Natural selection'}],\n"," 'ideal': 'd) Natural selection',\n"," 'option': ['a) Mutation',\n","  'b) Non-random mating',\n","  'c) Gene flow',\n","  'd) Natural selection'],\n"," 'task': '1'}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"markdown","id":"8ed62e6c-f146-4063-9ce7-a2a162b68cf3","metadata":{},"source":["### 构建自定义的Dataset和Collator"]},{"cell_type":"code","execution_count":7,"id":"eda38ba8-69e5-409f-aa8e-06223b949ca3","metadata":{},"outputs":[],"source":["#导入训练集\n","class sftDataset(Dataset):\n","    def __init__(self,data,tokenizer,doc_converter):\n","        #data是个list\n","        self.data=data\n","        self.tokenizer=tokenizer\n","        self.doc_converter=doc_converter\n","\n","    def __getitem__(self, index) :\n","        #把对应论文的内容concat到user content的后面。具体对pdf怎么处理由选手决定，此处仅是一个简单的示例。\n","        if \"pages\" in self.data[index]:\n","            #处理pdf并拼接\n","            parse_pdf_and_concate(self.data[index],self.doc_converter)\n","        input=self.data[index][\"input\"]\n","        ideal=extract_ideal_value(self.data[index][\"ideal\"])\n","        output=ideal\n","\n","        input.append({\"role\":\"assistant\",\"content\":output})\n","        #msg是个list：\n","        '''  msg= [\n","          {\"role\": \"system\", \"content\": \"You are an expert in the electrolytes field. Please answer the following multiple choice question correctly.\\nOnly write the option (e.g., a), b), c), or d)) without explanation.\"},\n","          {\"role\": \"user\", \"content\": \"In the upper paper, what are the minimum and maximum intramolecular distancesnm) of dimethyl carbonate?\\n\\na) 0.41/0.87\\nb) 0.49/0.67\\nc) 0.25/0.25\\nd) 0.25/0.38\"},\n","          {\"role\":\"assistant\",\"content\":\"a) 0.41/0.87\"},\n","            ]\n","        '''\n","        response=self.tokenizer.apply_chat_template(input,tokenize=False, add_generation_prompt=False)\n","        input=response.split(\"<|im_start|>assistant\\n\")[0]\n","        input+=\"<|im_start|>assistant\\n\"\n","        return dict(input_ids=input, labels=response)\n","    \n","    def __len__(self):\n","        return len(self.data)\n","\n","#把输入从字符串改为特定的token list\n","class Collator(object):\n","    def __init__(self,only_train_response,tokenizer):\n","        self.only_train_response=only_train_response\n","        self.tokenizer=tokenizer\n","        if self.tokenizer.pad_token_id is None:\n","            self.tokenizer.pad_token_id = self.tokenizer.unk_token_id\n","        \n","    def __call__(self,batch):\n","        input_texts=[d[\"input_ids\"] for d in batch]\n","        full_texts=[d[\"labels\"] for d in batch]\n","\n","        inputs=self.tokenizer(\n","            text=full_texts,\n","            text_target=input_texts,\n","            return_tensors=\"pt\",\n","            padding=\"longest\",\n","            max_length=1024,\n","            truncation=True,\n","            return_attention_mask=True,\n","        )\n","        labels=copy.deepcopy(inputs[\"input_ids\"])\n","        if self.only_train_response:\n","            # ignore padding\n","            labels[labels==self.tokenizer.pad_token_id]=-100\n","            # ignore input text\n","            labels[torch.where(inputs[\"labels\"] !=self.tokenizer.pad_token_id)]=-100\n","\n","        inputs[\"labels\"]=labels\n","        return inputs"]},{"cell_type":"code","execution_count":8,"id":"b7af5f74-6841-42a2-94e1-821ce441154c","metadata":{},"outputs":[],"source":["sft_dataset=sftDataset(train_data,tokenizer,converter)\n","only_train_response=True\n","data_collator=Collator(only_train_response,tokenizer)"]},{"cell_type":"code","execution_count":9,"id":"22ba3c37","metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': '<|im_start|>system\\nYou are a highly intelligent assistant who answers the following multiple choice question correctly.<|im_end|>\\n<|im_start|>system\\n<|im_end|>\\n<|im_start|>system\\nOnly write the answer down.<|im_end|>\\n<|im_start|>user\\nWhich of these evolutionary agents is most consistent at causing populations to become better suited to their environments over the course of generations?\\n\\na) Mutation\\n\\nb) Non-random mating\\n\\nc) Gene flow\\n\\nd) Natural selection<|im_end|>\\n<|im_start|>assistant\\n',\n"," 'labels': '<|im_start|>system\\nYou are a highly intelligent assistant who answers the following multiple choice question correctly.<|im_end|>\\n<|im_start|>system\\n<|im_end|>\\n<|im_start|>system\\nOnly write the answer down.<|im_end|>\\n<|im_start|>user\\nWhich of these evolutionary agents is most consistent at causing populations to become better suited to their environments over the course of generations?\\n\\na) Mutation\\n\\nb) Non-random mating\\n\\nc) Gene flow\\n\\nd) Natural selection<|im_end|>\\n<|im_start|>assistant\\nd) Natural selection<|im_end|>\\n<|im_start|>assistant\\nd) Natural selection<|im_end|>\\n'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["sft_dataset.__getitem__(0)"]},{"cell_type":"code","execution_count":12,"id":"aedb9881-3048-4210-9f86-e9c1455e2e26","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n","Collecting peft\n","  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/62/72/fcabddf222ec938c3cbd5616e5a72796938b5235897e07a1fcc2a8e7735e/peft-0.12.0-py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /opt/mamba/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: psutil in /opt/mamba/lib/python3.10/site-packages (from peft) (5.9.6)\n","Requirement already satisfied: tqdm in /opt/mamba/lib/python3.10/site-packages (from peft) (4.64.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/mamba/lib/python3.10/site-packages (from peft) (0.33.0)\n","Requirement already satisfied: transformers in /opt/mamba/lib/python3.10/site-packages (from peft) (4.43.2)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/mamba/lib/python3.10/site-packages (from peft) (0.24.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from peft) (23.2)\n","Requirement already satisfied: torch>=1.13.0 in /opt/mamba/lib/python3.10/site-packages (from peft) (2.4.0)\n","Requirement already satisfied: safetensors in /opt/mamba/lib/python3.10/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/mamba/lib/python3.10/site-packages (from peft) (1.26.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/mamba/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/mamba/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n","Requirement already satisfied: filelock in /opt/mamba/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n","Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n","Requirement already satisfied: triton==3.0.0 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.0.0)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n","Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: networkx in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n","Requirement already satisfied: sympy in /opt/mamba/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/mamba/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/mamba/lib/python3.10/site-packages (from transformers->peft) (2024.7.24)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/mamba/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.11)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2022.9.24)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/mamba/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Installing collected packages: peft\n","Successfully installed peft-0.12.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"ename":"Error","evalue":"INVALID mime type: status. Must be in the format \"type/subtype[;optionalparameter]\"","output_type":"error","traceback":["Error: INVALID mime type: status. Must be in the format \"type/subtype[;optionalparameter]\"\n","\tat new $i (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:152:48088)\n","\tat $i.text (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:152:47900)\n","\tat u (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:140368)\n","\tat m (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:141578)\n","\tat h (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:142333)\n","\tat Array.map (<anonymous>)\n","\tat /root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:138638\n","\tat /root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:138955\n","\tat /root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:138962\n","\tat Array.map (<anonymous>)\n","\tat e.jupyterNotebookModelToNotebookData (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:138214)\n","\tat e.NotebookSerializer.deserializeNotebook (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/extensions/ipynb/dist/ipynbMain.js:1:159381)\n","\tat g.$dataToNotebook (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:159:4613)\n","\tat y.S (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:151:5980)\n","\tat y.Q (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:151:5746)\n","\tat y.M (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:151:4739)\n","\tat y.L (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:151:3830)\n","\tat i.value (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:151:2297)\n","\tat n.B (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:737)\n","\tat n.fire (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:954)\n","\tat s.fire (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:14453)\n","\tat i.value (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:177:8655)\n","\tat n.B (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:737)\n","\tat n.fire (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:954)\n","\tat s.fire (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:14453)\n","\tat d.A (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:17612)\n","\tat i.value (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:15970)\n","\tat n.B (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:737)\n","\tat n.fire (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:83:954)\n","\tat m.acceptChunk (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:12199)\n","\tat /root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:97:11469\n","\tat Socket.v (/root/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/vs/workbench/api/node/extensionHostProcess.js:174:14266)\n","\tat Socket.emit (node:events:519:28)\n","\tat addChunk (node:internal/streams/readable:559:12)\n","\tat readableAddChunkPushByteMode (node:internal/streams/readable:510:3)\n","\tat Readable.push (node:internal/streams/readable:390:5)\n","\tat Pipe.onStreamRead (node:internal/stream_base_commons:191:23)"]}],"source":["!pip install peft"]},{"cell_type":"code","execution_count":9,"id":"40f23ebe-23ff-458e-8b0d-fcd63ff72df8","metadata":{},"outputs":[],"source":["from peft import LoraConfig,TaskType,get_peft_model,PeftModel"]},{"cell_type":"markdown","id":"9f6392dd-078f-4edd-a13f-c4d1c0e2306c","metadata":{},"source":["### 定义lora参数"]},{"cell_type":"code","execution_count":10,"id":"02d11466-2842-4ca1-9356-44ae130b0786","metadata":{},"outputs":[],"source":["#定义训练参数\n","args = TrainingArguments(\n","    output_dir=\"./personal/Qwen2_instruct_lora\",#设置输出路径\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=1,\n","    logging_steps=10,\n","    num_train_epochs=3,\n","    save_steps=500,\n","    learning_rate=1e-4,\n","    save_on_each_node=True,\n","    gradient_checkpointing=False\n",")\n","\n","#定义lora参数\n","from peft import LoraConfig,TaskType,get_peft_model,PeftModel\n","config=LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n","    inference_mode=False,\n","    r=8,\n","    lora_alpha=32,\n","    lora_dropout=0.1\n",")\n"]},{"cell_type":"markdown","id":"51319bab-3024-4dcb-b3fc-e65932c3520b","metadata":{},"source":["### 训练"]},{"cell_type":"code","execution_count":11,"id":"218488fb-7821-4d87-a498-bf4ed73a5fa2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected kernel version 5.4.250, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]},{"name":"stdout","output_type":"stream","text":["定义Trainer之前的显存情况:\n","显存分配: 0.23 GB\n","显存预留: 0.26 GB\n","定义Trainer之后的显存情况:\n","显存分配: 14.92 GB\n","显存预留: 15.03 GB\n","begin! : /root/code/pdfs/10.1016_j.mprp.2018.02.001.pdf\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: content stream objects stream 565 0 (content, offset 1712): parse error while reading object\n","WARNING: content stream objects stream 573 0 (content, offset 24): treating unexpected array close token as null\n","WARNING: content stream objects stream 573 0, content at offset 0: operation for array attempted on object of type string: treating as empty\n"]},{"name":"stdout","output_type":"stream","text":["end! : /root/code/pdfs/10.1016_j.mprp.2018.02.001.pdf\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='14' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 14/216 05:23 < 1:30:46, 0.04 it/s, Epoch 0.18/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["begin! : /root/code/pdfs/10.1021_acs.orglett.6b01704.pdf\n","end! : /root/code/pdfs/10.1021_acs.orglett.6b01704.pdf\n","begin! : /root/code/pdfs/10.1016_j.polymer.2014.12.060.pdf\n","end! : /root/code/pdfs/10.1016_j.polymer.2014.12.060.pdf\n"]},{"name":"stderr","output_type":"stream","text":["An unexpected error occurred while opening the document 10.1021_jacs.6b05418.pdf\n","Traceback (most recent call last):\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/datamodel/document.py\", line 93, in __init__\n","    self._backend = pdf_backend(\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/backend/docling_parse_backend.py\", line 193, in __init__\n","    self._pdoc = pdfium.PdfDocument(path_or_stream)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 78, in __init__\n","    self.raw, to_hold, to_close = _open_pdf(self._input, self._password, self._autoclose)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 678, in _open_pdf\n","    raise PdfiumError(f\"Failed to load document (PDFium: {pdfium_i.ErrorToStr.get(err_code)}).\")\n","pypdfium2._helpers.misc.PdfiumError: Failed to load document (PDFium: Data format error).\n"]},{"name":"stdout","output_type":"stream","text":["begin! : /root/code/pdfs/10.1021_jacs.6b05418.pdf\n","Error PDF is:  /root/code/pdfs/10.1021_jacs.6b05418.pdf\n","begin! : /root/code/pdfs/US9750738.pdf\n","end! : /root/code/pdfs/US9750738.pdf\n","begin! : /root/code/pdfs/10.1038_srep14202.pdf\n","end! : /root/code/pdfs/10.1038_srep14202.pdf\n","begin! : /root/code/pdfs/10.1002_cjoc.201500265.pdf\n","end! : /root/code/pdfs/10.1002_cjoc.201500265.pdf\n","begin! : /root/code/pdfs/10.1021_acs.orglett.6b01658.pdf\n","end! : /root/code/pdfs/10.1021_acs.orglett.6b01658.pdf\n","begin! : /root/code/pdfs/10.1002_asia.201402019.pdf\n","end! : /root/code/pdfs/10.1002_asia.201402019.pdf\n","begin! : /root/code/pdfs/10.1021_acs.orglett.6b01595.pdf\n","end! : /root/code/pdfs/10.1021_acs.orglett.6b01595.pdf\n","begin! : /root/code/pdfs/10.1016_j.matchar.2018.06.029.pdf\n"]},{"name":"stderr","output_type":"stream","text":["An unexpected error occurred while opening the document 10.1016_j.matchar.2018.06.029.pdf\n","Traceback (most recent call last):\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/datamodel/document.py\", line 93, in __init__\n","    self._backend = pdf_backend(\n","  File \"/root/miniconda3/lib/python3.10/site-packages/docling/backend/docling_parse_backend.py\", line 193, in __init__\n","    self._pdoc = pdfium.PdfDocument(path_or_stream)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 78, in __init__\n","    self.raw, to_hold, to_close = _open_pdf(self._input, self._password, self._autoclose)\n","  File \"/root/miniconda3/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 678, in _open_pdf\n","    raise PdfiumError(f\"Failed to load document (PDFium: {pdfium_i.ErrorToStr.get(err_code)}).\")\n","pypdfium2._helpers.misc.PdfiumError: Failed to load document (PDFium: Data format error).\n"]},{"name":"stdout","output_type":"stream","text":["Error PDF is:  /root/code/pdfs/10.1016_j.matchar.2018.06.029.pdf\n","begin! : /root/code/pdfs/10.1021_je3003089.pdf\n","end! : /root/code/pdfs/10.1021_je3003089.pdf\n","begin! : /root/code/pdfs/10.1021_je3003089.pdf\n","end! : /root/code/pdfs/10.1021_je3003089.pdf\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 404.00 MiB (GPU 0; 23.65 GiB total capacity; 22.48 GiB already allocated; 28.75 MiB free; 22.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m定义Trainer之后的显存情况:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m print_memory_usage()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/accelerator.py:2159\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2159\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 404.00 MiB (GPU 0; 23.65 GiB total capacity; 22.48 GiB already allocated; 28.75 MiB free; 22.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["lora_model=get_peft_model(model,config)\n","# 打印显存占用情况\n","def print_memory_usage():\n","    allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # 转换为GB\n","    reserved = torch.cuda.memory_reserved() / (1024 ** 3)  # 转换为GB\n","    print(f\"显存分配: {allocated:.2f} GB\")\n","    print(f\"显存预留: {reserved:.2f} GB\")\n","\n","# 打印显存占用情况\n","print(\"定义Trainer之前的显存情况:\")\n","print_memory_usage()\n","#定义trainer\n","trainer=Trainer(\n","    model=lora_model,\n","    args=args,\n","    data_collator=data_collator,\n","    train_dataset=sft_dataset,\n",")\n","print(\"定义Trainer之后的显存情况:\")\n","print_memory_usage()\n","trainer.train()\n"]},{"cell_type":"code","execution_count":17,"id":"43ff77d0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["定义Trainer之前的显存情况:\n","显存分配: 0.00 GB\n","显存预留: 0.00 GB\n","模型大小: 14973.64 MB\n"]}],"source":["def print_memory_usage():\n","    allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # 转换为GB\n","    reserved = torch.cuda.memory_reserved() / (1024 ** 3)  # 转换为GB\n","    print(f\"显存分配: {allocated:.2f} GB\")\n","    print(f\"显存预留: {reserved:.2f} GB\")\n","print(\"定义Trainer之前的显存情况:\")\n","print_memory_usage()\n","def get_model_size(model):\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n","    return size_all_mb\n","\n","# Assuming lora_model is your model\n","model_size = get_model_size(model)\n","print(f\"模型大小: {model_size:.2f} MB\")"]},{"cell_type":"markdown","id":"51ab9c09-8000-4677-9942-99135610114f","metadata":{},"source":["### 【补充】平台使用帮助\n","baseline中模型的输出结果、微调/合并示例中模型权重的保存位置都可以根据选手的需要进行修改，可以考虑保存到个人的文件夹下（/personal/），然后再挂载到创建的数据集中。\n","平台数据集的使用规则可以参考：\n","https://bohrium-doc.dp.tech/docs/userguide/Dataset/"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
